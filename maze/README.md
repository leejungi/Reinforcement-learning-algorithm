# RL with Maze path finding
Input maze size, then the wall will be generated by random function.

If you want to input your maze, then use load in Environment.py

# Result
Q-learning vs SARSA
If the size of maze increases, Q-learning is hard to find the path. So i change 'epilson' to 'epilson*iteration/num_episode' in epilson-greedy method. Then Q-learning can find the optimal path. 
SARSA can find path from start to end point without changing epilson. But it needs more cycles to find the optimal path. 
